{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jJuTcO7WOc07"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HxtTlj3pObE8"
   },
   "outputs": [],
   "source": [
    "##データの読み込み\n",
    "DATA_PATH='./'\n",
    "\n",
    "f=open(DATA_PATH+\"/train_data201604_without_normalize_2.txt\",\"rb\")\n",
    "pre_pre_data=pickle.load(f)\n",
    "#別に取得したデータを結合させる(201604のデータ)\n",
    "f=open(DATA_PATH+\"/train_data201606_without_normalize_2.txt\",\"rb\")\n",
    "extend_data=pickle.load(f)\n",
    "\n",
    "\n",
    "f=open(DATA_PATH+\"/train_label201604_2.txt\",\"rb\")\n",
    "label=pickle.load(f)\n",
    "##別に取得したデータを結合させる(201604のデータ)\n",
    "f=open(DATA_PATH+\"/train_label201606_2.txt\",\"rb\")\n",
    "extend_label=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origine length: 133215\n",
      "extend length: 133215\n",
      "append data: 266430\n"
     ]
    }
   ],
   "source": [
    "print(\"origine length: %d\" % len(pre_pre_data))\n",
    "print(\"extend length: %d\" % len(extend_data))\n",
    "\n",
    "##追加データを配列に加える処理\n",
    "##特徴量\n",
    "for i in range(len(extend_data)):\n",
    "    pre_pre_data.append(extend_data[i])\n",
    "##正解ラベル\n",
    "for i in range(len(extend_label)):\n",
    "    label.append(extend_label[i])\n",
    "\n",
    "#####データの長さの確認\n",
    "print(\"append data: %d\" % len(pre_pre_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6911,
     "status": "ok",
     "timestamp": 1545265276611,
     "user": {
      "displayName": "斉藤慎太郎",
      "photoUrl": "",
      "userId": "08781351261207481557"
     },
     "user_tz": -540
    },
    "id": "oyBtWs4Kie6R",
    "outputId": "0339d27b-3646-4932-baf4-634d134a343a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266430\n",
      "266430\n",
      "0.307923281913\n"
     ]
    }
   ],
   "source": [
    "print(len(pre_pre_data))\n",
    "print(len(label))\n",
    "print(sum(label)/len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7404,
     "status": "ok",
     "timestamp": 1545265277120,
     "user": {
      "displayName": "斉藤慎太郎",
      "photoUrl": "",
      "userId": "08781351261207481557"
     },
     "user_tz": -540
    },
    "id": "NJ9SM1R8KrKx",
    "outputId": "e68cce03-4c06-42c1-d798-ab8332e592b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 11136     10      7]\n",
      " [144351     10      7]]\n"
     ]
    }
   ],
   "source": [
    "##全データのうちの最大値をとるindexを確認\n",
    "p_data=np.array(pre_pre_data)\n",
    "max_index=np.argwhere(p_data == p_data.max())\n",
    "print(max_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##すべて0のデータがないか確認\n",
    "zero_index=[]\n",
    "for i in range(len(p_data)):\n",
    "    if p_data[i].max == 0:\n",
    "        zero_index.append(1)\n",
    "    else:\n",
    "        zero_index.append(0)\n",
    "sum(zero_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7398,
     "status": "ok",
     "timestamp": 1545265277121,
     "user": {
      "displayName": "斉藤慎太郎",
      "photoUrl": "",
      "userId": "08781351261207481557"
     },
     "user_tz": -540
    },
    "id": "ewm6UOPQAXGe",
    "outputId": "1807fafd-890c-413b-d752-7c92279823d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09316518410088954"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##だいたいどれくらい以上の値で全データのうちに占めるのかの計算\n",
    "len(np.argwhere(p_data>140))/len(p_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dYYZrqKlLE-C"
   },
   "outputs": [],
   "source": [
    "###極端な値が含まれているデータを除いて新しいデータセットを作ってみる\n",
    "##ここでは、外れ値として上位約9%の値を除いたデータセットにする\n",
    "pp_data=[]\n",
    "pp_label=[]\n",
    "for i in range(len(pre_pre_data)):\n",
    "    if (np.max(pre_pre_data[i]) <=140 ):\n",
    "        pp_data.append(pre_pre_data[i])\n",
    "        pp_label.append(label[i])\n",
    "    \n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##特徴量と正解ラベルのデータを同じindexで並べ替える\n",
    "random_index=[]\n",
    "for i in range(len(pp_data)):\n",
    "    random_index.append(i)\n",
    "    \n",
    "##random_indexをシャッフルする\n",
    "random_index=np.random.permutation(random_index)\n",
    "\n",
    "##random_indexを使って、新しいデータ配列を作成する\n",
    "pp_data2=[]\n",
    "pp_label2=[]\n",
    "for i in random_index:\n",
    "    pp_data2.append(pp_data[i])\n",
    "    pp_label2.append(pp_label[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 各画像ごとの各列の正解ラベルに対しての合計をnumpyで格納して、各列の正解ラベルに対しての相関係数を求める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "soukan=[]\n",
    "num_sum=[]\n",
    "\n",
    "soukan_pre_data=np.array(pp_data2)\n",
    "soukan_label=np.array(pp_label2)\n",
    "\n",
    "sum_list = [[] for i in range(11)]\n",
    "col_list = [[] for i in range(11)]\n",
    "##各ユーザーごとに各列の合計を取ってくる\n",
    "for i in range(len(pp_data2)):\n",
    "    ##i番目のユーザーの各列の合計\n",
    "    num_sum=soukan_pre_data[i].sum(axis=0)\n",
    "    for j in range(len(num_sum)):\n",
    "        sum_list[j].append(num_sum[j])\n",
    "##各特徴量を正解ラベルに対して相関を取る        \n",
    "for i in range(11):\n",
    "    col_list[i].append(np.corrcoef(sum_list[i] , soukan_label)[0][1])\n",
    "\n",
    "##相関の高いindex順に並べ替える\n",
    "num_list=[]\n",
    "for i in range(len(col_list)):\n",
    "    num = np.argsort(np.array(col_list).flatten())[::-1][i]\n",
    "    num_list.append(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04196269420740166], [0.034791228451347252], [0.17801460776674793], [0.0057495750408455143], [0.019707631682382036], [0.049351184300400149], [0.11703170244132817], [0.012661345003537869], [0.065938722149423493], [0.1488590251135852], [0.017949394562392466]]\n",
      "[2, 9, 6, 8, 5, 0, 1, 4, 10, 7, 3]\n"
     ]
    }
   ],
   "source": [
    "print(col_list)\n",
    "print(num_list)\n",
    "##指定した順に列を並べ替える\n",
    "pp_data3=[]\n",
    "\n",
    "for i in range(len(pp_data2)):\n",
    "    data=pp_data2[i][:, num_list]\n",
    "    pp_data3.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''0以外のところを上限256として反転させる'''\n",
    "pp_reverse=[]\n",
    "for i in range(len(pp_data3)):\n",
    "    add_data=np.where(pp_data3[i]>0 ,256-pp_data3[i],pp_data3[i])\n",
    "    pp_reverse.append(add_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|            Variable Name|    Memory|\n",
      " ------------------------------------ \n",
      "|              extend_data|   1080112|\n",
      "|             extend_label|   1080112|\n",
      "|                    label|   2190072|\n",
      "|                   p_data| 703375328|\n",
      "|                  pp_data|   2115952|\n",
      "|                 pp_data2|   2115952|\n",
      "|                 pp_data3|   2115952|\n",
      "|                 pp_label|   2115952|\n",
      "|                pp_label2|   2115952|\n",
      "|               pp_reverse|   2115952|\n",
      "|             pre_pre_data|   2190072|\n",
      "|             random_index|   2022800|\n",
      "|             soukan_label|   1011448|\n",
      "|          soukan_pre_data| 667492448|\n",
      "|               zero_index|   2380488|\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"{}{: >25}{}{: >10}{}\".format('|','Variable Name','|','Memory','|'))\n",
    "print(\" ------------------------------------ \")\n",
    "for var_name in dir():\n",
    "    if not var_name.startswith(\"_\") and sys.getsizeof(eval(var_name)) > 10000: #ここだけアレンジ\n",
    "        print(\"{}{: >25}{}{: >10}{}\".format('|',var_name,'|',sys.getsizeof(eval(var_name)),'|'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "529"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del label,p_data,pp_data,pp_data2,pp_data3,pp_label,pre_pre_data,soukan_label,soukan_pre_data,zero_index\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### テストデータだけ切り離し、標準化して保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive data:67971\n",
      "negative data:160833\n"
     ]
    }
   ],
   "source": [
    "test_buy=[]\n",
    "test_nobuy=[]\n",
    "test_index=[]\n",
    "x_test_add_noise=[]\n",
    "y_test_add_noise=[]\n",
    "length=int(len(pp_reverse)*0.1)\n",
    "for i in range(length):\n",
    "    index=int(np.random.choice(random_index,1))\n",
    "    test_index.append(index)\n",
    "    \n",
    "for i in test_index:\n",
    "    x_test_add_noise.append(pp_reverse[i])\n",
    "    y_test_add_noise.append(pp_label2[i])\n",
    "    \n",
    "    \n",
    "train_index=list(set(random_index)-set(test_index))\n",
    "###正例、不例のサンプリングをする\n",
    "##正例、不例のindexを取得しておく\n",
    "\n",
    "buy=[]\n",
    "no_buy=[]\n",
    "for i in train_index:\n",
    "    if pp_label2[i]==1:\n",
    "        buy.append(i)\n",
    "    else:\n",
    "        no_buy.append(i)\n",
    "print('positive data:{}'.format(len(buy)))\n",
    "print('negative data:{}'.format(len(no_buy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###train\n",
    "train_buy=[]\n",
    "train_nobuy=[]\n",
    "length=int(len(pp_reverse)*0.9*0.9)\n",
    "for i in range(length):\n",
    "    index=int(np.random.choice(buy,1))\n",
    "    train_buy.append(index)\n",
    "for i in range(length):\n",
    "    index=int(np.random.choice(no_buy,1))\n",
    "    train_nobuy.append(index)\n",
    "    \n",
    "buy2=list(set(buy)-set(train_buy))\n",
    "no_buy2=list(set(no_buy)-set(train_nobuy))\n",
    "\n",
    "##train\n",
    "x_train_add_noise=[]\n",
    "y_train_add_noise=[]\n",
    "\n",
    "valid_x_test_add_noise=[]\n",
    "valid_y_test_add_noise=[]\n",
    "\n",
    "for i in train_buy:\n",
    "    x_train_add_noise.append(pp_reverse[i])\n",
    "    y_train_add_noise.append(pp_label2[i])\n",
    "for i in train_nobuy:\n",
    "    x_train_add_noise.append(pp_reverse[i])\n",
    "    y_train_add_noise.append(pp_label2[i])\n",
    "    \n",
    "for i in buy2:\n",
    "    valid_x_test_add_noise.append(pp_reverse[i])\n",
    "    valid_y_test_add_noise.append(pp_label2[i])\n",
    "for i in no_buy2:\n",
    "    valid_x_test_add_noise.append(pp_reverse[i])\n",
    "    valid_y_test_add_noise.append(pp_label2[i])\n",
    "\n",
    "def scale(X):\n",
    "    \"\"\"データ行列Xを属性ごとに標準化したデータを返す\"\"\"\n",
    "    # 属性の数 (列の数)\n",
    "    delta=1e-3\n",
    "    col = X[0].shape[1]\n",
    "\n",
    "   \n",
    "   # 属性ごとにデータを標準化or正則化\n",
    "    for j in range(len(X)):\n",
    "        for i in range(col):\n",
    "            # 属性ごとに平均値と標準偏差を計算\n",
    "            mu = np.mean(X[j][:,[i]])\n",
    "            sigma = np.std(X[j][:,[i]])\n",
    "            X[j][:,[i]]= (X[j][:,[i]]- mu) / (sigma+delta)\n",
    "            \n",
    "    return X\n",
    "  \n",
    "##各ユーザーデータを列ごとに標準化(列の値が全て0の場合を考えて、分母に極小の値を加えて標準化)\n",
    "pp_data_np=np.asarray(x_test_add_noise)\n",
    "pre_data2=scale(pp_data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "標準化の際にnanが生じている場合に備えてnan削除の処理\n",
    "'''\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "len(np.unique(np.where(np.isnan(pre_data2))[0]))\n",
    "nan_list=np.unique(np.where(np.isnan(pre_data2))[0])\n",
    "\n",
    "##nanの部分を削除\n",
    "dellist = lambda items, indexes: [item for index, item in enumerate(items) if index not in indexes]\n",
    "pre_data3=dellist(pre_data2,nan_list)\n",
    "label=dellist(y_test_add_noise,nan_list)\n",
    "\n",
    "'''特徴量:pre_data3   ラベル:label'''\n",
    "##データの長さがずれないか確認\n",
    "print(len(label))\n",
    "print(len(pre_data3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##test dataの保存\n",
    "import pickle\n",
    "f=open(\"./x_test_corr_high_test_without_add_some_noise_samesample.txt\",\"wb\")\n",
    "pickle.dump(pre_data3, f)\n",
    "f=open(\"./y_test_corr_high_test_without_add_some_noise_samesample.txt\",\"wb\")\n",
    "pickle.dump(label, f)\n",
    "\n",
    "print(sum(label)/len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##validation 標準化\n",
    "pp_data_np=np.asarray(valid_x_test_add_noise)\n",
    "pre_data2=scale(pp_data_np)\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "len(np.unique(np.where(np.isnan(pre_data2))[0]))\n",
    "nan_list=np.unique(np.where(np.isnan(pre_data2))[0])\n",
    "\n",
    "##nanの部分を削除\n",
    "dellist = lambda items, indexes: [item for index, item in enumerate(items) if index not in indexes]\n",
    "pre_data3=dellist(pre_data2,nan_list)\n",
    "label=dellist(valid_y_test_add_noise,nan_list)\n",
    "\n",
    "'''特徴量:pre_data3   ラベル:label'''\n",
    "##データの長さがずれないか確認\n",
    "print(len(label))\n",
    "print(len(pre_data3))\n",
    "print(sum(label)/len(label))\n",
    "\n",
    "##valid\n",
    "f=open(\"./validation_x_test_corr_high_test_without_add_some_noise_samesample.txt\",\"wb\")\n",
    "pickle.dump(pre_data3, f)\n",
    "f=open(\"./validation_y_test_corr_high_test_without_add_some_noise_samesample.txt\",\"wb\")\n",
    "pickle.dump(label, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###正例、不例のサンプリングをする\n",
    "##正例、不例のindexを取得しておく\n",
    "\n",
    "buy=[]\n",
    "no_buy=[]\n",
    "for i in range(len(y_train_add_noise)):\n",
    "    if y_train_add_noise[i]==1:\n",
    "        buy.append(i)\n",
    "    else:\n",
    "        no_buy.append(i)\n",
    "print('positive data:{}'.format(len(buy)))\n",
    "print('negative data:{}'.format(len(no_buy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ水増し"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''データの水増しを行う\n",
    "不例を20万枚増やして正例データを同じ数になるようにしてみる\n",
    "正例、不例ともにごま塩加工で増やす\n",
    "'''\n",
    "##塩の割合を指定\n",
    "s_vs_p = 0.7\n",
    "##全体的にごま塩を増やしたいなら、ここを変える\n",
    "amount = 0.15\n",
    "from skimage import transform\n",
    "import random\n",
    "\n",
    "\n",
    "'''正例、不例ともに画素15%にごま塩加工'''\n",
    "salt_papper_posi_x=[]\n",
    "salt_papper_posi_y=[]\n",
    "salt_papper_nega_x=[]\n",
    "salt_papper_nega_y=[]\n",
    "\n",
    "salt_papper_posi_x2=[]\n",
    "salt_papper_posi_y2=[]\n",
    "salt_papper_nega_x2=[]\n",
    "salt_papper_nega_y2=[]\n",
    "\n",
    "no_buy_loop = 200000-len(no_buy)\n",
    "\n",
    "'''負例データ'''\n",
    "for j in range(no_buy_loop):\n",
    "    ##データindexのランダム選択\n",
    "    nega=int(np.random.choice(no_buy,1))\n",
    "    src = x_train_add_noise[nega]\n",
    "    sp_img = src.copy()\n",
    "    # 塩モード\n",
    "    num_salt = np.ceil(amount * src.size * s_vs_p)\n",
    "    coords = [np.random.randint(0, i , int(num_salt)) for i in sp_img.shape]\n",
    "    ##代入する値をランダムに選択(200から255)\n",
    "    input_number = int(np.random.randint(116, 256 ,1))\n",
    "    sp_img[coords] = input_number\n",
    "\n",
    "    # 胡椒モード\n",
    "    num_pepper = np.ceil(amount* src.size * (1. - s_vs_p))\n",
    "    coords = [np.random.randint(0, i , int(num_pepper)) for i in sp_img.shape]\n",
    "    sp_img[coords] = 0\n",
    "    \n",
    "    salt_papper_nega_x.append(sp_img)\n",
    "    salt_papper_nega_y.append(y_train_add_noise[nega])\n",
    "    \n",
    "\n",
    "\n",
    "buy_loop = 200000-len(buy)\n",
    "\n",
    "'''正例データ'''\n",
    "for j in range(buy_loop):\n",
    "    ##データindexのランダム選択\n",
    "    posi=int(np.random.choice(buy,1))\n",
    "    src = x_train_add_noise[posi]\n",
    "    sp_img = src.copy()\n",
    "    # 塩モード\n",
    "    num_salt = np.ceil(amount * src.size * s_vs_p)\n",
    "    coords = [np.random.randint(0, i , int(num_salt)) for i in sp_img.shape]\n",
    "    ##代入する値をランダムに選択(200から255)\n",
    "    input_number = int(np.random.randint(116, 256 ,1))\n",
    "    sp_img[coords] = input_number\n",
    "\n",
    "    # 胡椒モード\n",
    "    num_pepper = np.ceil(amount* src.size * (1. - s_vs_p))\n",
    "    coords = [np.random.randint(0, i , int(num_pepper)) for i in sp_img.shape]\n",
    "    sp_img[coords] = 0\n",
    "    \n",
    "    salt_papper_posi_x.append(sp_img)\n",
    "    salt_papper_posi_y.append(y_train_add_noise[posi])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###データappend\n",
    "for i in range(len(salt_papper_posi_x)):\n",
    "    x_train_add_noise.append(salt_papper_posi_x[i])\n",
    "    y_train_add_noise.append(salt_papper_posi_y[i])\n",
    "    \n",
    "for i in range(len(salt_papper_nega_x)):\n",
    "    x_train_add_noise.append(salt_papper_nega_x[i])\n",
    "    y_train_add_noise.append(salt_papper_nega_y[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 標準化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##各ユーザーデータを列ごとに標準化(列の値が全て0の場合を考えて、分母に極小の値を加えて標準化)\n",
    "pp_data_np=np.asarray(x_train_add_noise)\n",
    "pre_data2=scale(pp_data_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "標準化の際にnanが生じている場合に備えてnan削除の処理\n",
    "'''\n",
    "\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "len(np.unique(np.where(np.isnan(pre_data2))[0]))\n",
    "nan_list=np.unique(np.where(np.isnan(pre_data2))[0])\n",
    "\n",
    "##nanの部分を削除\n",
    "dellist = lambda items, indexes: [item for index, item in enumerate(items) if index not in indexes]\n",
    "pre_data3=dellist(pre_data2,nan_list)\n",
    "label=dellist(y_train_add_noise,nan_list)\n",
    "\n",
    "'''特徴量:pre_data3   ラベル:label'''\n",
    "##データの長さがずれないか確認\n",
    "print(len(label))\n",
    "print(len(pre_data3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##train保存\n",
    "##train\n",
    "f = open('./validation_x_train_corr_high_test_without_add_some_noise_samesample.txt', 'wb')\n",
    "pickle.dump(pre_data3, f)\n",
    "f = open('./validation_y_train_corr_high_test_without_add_some_noise_samesample.txt', 'wb')\n",
    "pickle.dump(label, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(label)/len(label))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "purchase_predcit2_data_modify.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
